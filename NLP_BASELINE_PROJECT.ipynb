{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Train File for en-us text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line to Article mapping has been stored for later optimizations on the training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns {Line : Article}\n",
    "\n",
    "def readnormalcorpus():\n",
    "    linetest=0\n",
    "    corpus={}\n",
    "    fi=open(\"normal_test.txt\",\"r\")\n",
    "    for line in fi:\n",
    "        line=line.lower()\n",
    "        linetest+=1\n",
    "        if linetest > 1000:\n",
    "            break\n",
    "        corpus[[((line[:-1].split(\"\\t\")))[2]][0]]=[((line[:-1].split(\"\\t\")))[0]][0];\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Train File for Simple Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns {Line : Article}\n",
    "\n",
    "def readsimplecorpus():\n",
    "    linetest=0\n",
    "    corpus={}\n",
    "    fi=open(\"simple_test.txt\",\"r\")\n",
    "    for line in fi:\n",
    "        line=line.lower()\n",
    "        linetest+=1\n",
    "        if linetest > 1000:\n",
    "            break\n",
    "        corpus[[((line[:-1].split(\"\\t\")))[2]][0]]=[((line[:-1].split(\"\\t\")))[0]][0];\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import tee, izip\n",
    "\n",
    "def window(iterable, size):\n",
    "    iters = tee(iterable, size)\n",
    "    for i in xrange(1, size):\n",
    "        for each in iters[i:]:\n",
    "            next(each, None)\n",
    "    return izip(*iters)\n",
    "\n",
    "def tri_model():\n",
    "    \n",
    "    normal_corpus = readnormalcorpus()\n",
    "    simple_corpus = readsimplecorpus()\n",
    "    \n",
    "    tgm_normal={}\n",
    "    tgm_simple={}\n",
    "        \n",
    "    for i in normal_corpus.keys():\n",
    "        for each in window(i.split(), 3):\n",
    "            temp=list(each)\n",
    "            if tgm_normal.has_key(tuple(temp)):\n",
    "                tgm_normal[tuple(list(each))]+=1\n",
    "            else:\n",
    "                tgm_normal[tuple(list(each))]=1\n",
    "    \n",
    "                \n",
    "    for i in simple_corpus.keys():\n",
    "        for each in window(i.split(), 3):\n",
    "            temp=list(each)\n",
    "            if tgm_simple.has_key(tuple(temp)):\n",
    "                tgm_simple[tuple(list(each))]+=1\n",
    "            else:\n",
    "                tgm_simple[tuple(list(each))]=1\n",
    "\n",
    "    return tgm_normal,tgm_simple\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Normal Corpus from simple trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_normal_corpus(tgm_normal,tgm_simple):\n",
    "    tgm_normal_cleaned={}\n",
    "    for i in tgm_normal.keys():\n",
    "        if i not in tgm_simple.keys():\n",
    "            tgm_normal_cleaned[i]=tgm_normal[i]\n",
    "    return tgm_normal_cleaned "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, Defining a Naive Bias Model for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a trigram input and does a simple vs normal classification. As the trigram which is normal is also present in simple we classify it in simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "different kinds of the 1970s often have little or no concavity , whereas 1980s models have deeper concavities and steeper kicktails .\n",
      "6e-05\n",
      "9.71558045215e-05\n",
      "NORMAL\n"
     ]
    }
   ],
   "source": [
    "def naive_classifier(sentence):\n",
    "    tgm_normal,tgm_simple=tri_model()\n",
    "    sentence=sentence.lower()\n",
    "    score_simple=0\n",
    "    score_normal=0\n",
    "    total_simple=sum(tgm_simple.values())\n",
    "    total_normal=sum(tgm_normal.values())\n",
    "    print sentence\n",
    "    for each in window(sentence.split(), 3):\n",
    "        temp=list(each)\n",
    "        if(tgm_simple.has_key(tuple(temp))):\n",
    "            score_simple+=tgm_simple[tuple(temp)]*1.0/total_simple\n",
    "        else :\n",
    "            score_simple+=0.000003\n",
    "        if(tgm_normal.has_key(tuple(temp))):\n",
    "            score_normal+=tgm_normal[tuple(temp)]*1.0/total_normal\n",
    "        else:\n",
    "            score_normal+=0.000003\n",
    "    \n",
    "    print score_simple\n",
    "    print score_normal\n",
    "    if(score_normal>score_simple):\n",
    "        print \"NORMAL\"\n",
    "    else:\n",
    "        print \"SIMPLE\"\n",
    "\n",
    "sentence=\"Different kinds of the 1970s often have little or no concavity , whereas 1980s models have deeper concavities and steeper kicktails .\"        \n",
    "naive_classifier(sentence)\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a logestic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True, verbose=False):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "        \n",
    "        # weights initialization\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.__sigmoid(z)\n",
    "            gradient = np.dot(X.T, (h - y)) / y.size\n",
    "            self.theta -= self.lr * gradient\n",
    "            \n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.__sigmoid(z)\n",
    "            loss = self.__loss(h, y)\n",
    "                \n",
    "            if(self.verbose ==True and i % 10000 == 0):\n",
    "                print loss\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "    \n",
    "        return self.__sigmoid(np.dot(X, self.theta))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_prob(X).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making X and Y for Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makexandy(tgm_normal,tgm_simple,glo_idx):\n",
    "    for i in tgm_normal:\n",
    "        for j in i:\n",
    "            if j not in glo_idx:\n",
    "                glo_idx.append(j)\n",
    "    for i in tgm_simple:\n",
    "        for j in i:\n",
    "            if j not in glo_idx:\n",
    "                glo_idx.append(j)\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    \n",
    "    for i in tgm_normal:\n",
    "        temp=[]\n",
    "        for j in i:\n",
    "            temp.append(glo_idx.index(j))\n",
    "        X.append(temp)\n",
    "    \n",
    "    for i in range(0,len(X)):\n",
    "        Y.append(0)\n",
    "    \n",
    "    for i in tgm_simple:\n",
    "        temp=[]\n",
    "        for j in i:\n",
    "            temp.append(glo_idx.index(j))\n",
    "        X.append(temp)\n",
    "        \n",
    "    for i in range(0,len(tgm_simple)):\n",
    "        Y.append(1)\n",
    "        \n",
    "    return X,Y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make X for test data and vectorize it (Using Trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import tee, izip\n",
    "\n",
    "def window(iterable, size):\n",
    "    iters = tee(iterable, size)\n",
    "    for i in xrange(1, size):\n",
    "        for each in iters[i:]:\n",
    "            next(each, None)\n",
    "    return izip(*iters)\n",
    "\n",
    "def makeXfortest(sentence,glo_idx):\n",
    "    X_temp=[]\n",
    "    for each in window(sentence.split(), 3):\n",
    "        X_temp.append(list(each))\n",
    "\n",
    "    X=[]\n",
    "    for i in X_temp:\n",
    "        temp=[]\n",
    "        for j in i:\n",
    "            if j in glo_idx:\n",
    "                temp.append(glo_idx.index(j))\n",
    "            else:\n",
    "                temp.append(-1)\n",
    "        X.append(temp)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in multiply\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........WITHOUT CLEANING...........\n",
      "_____ACCURACY_____\n",
      "49.6829034321\n",
      "_____PRECISION_____\n",
      "59.7730259994\n",
      "_____RECALL_____\n",
      "74.6397117694\n",
      "_____F1 SCORE_____\n",
      "33.1921029676\n",
      ".............WITH CLEANING...........\n",
      "_____ACCURACY_____\n",
      "40.0108769545\n",
      "_____PRECISION_____\n",
      "40.0108769545\n",
      "_____RECALL_____\n",
      "100.0\n",
      "_____F1 SCORE_____\n",
      "28.5769776069\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "glo_idx=[]\n",
    "tgm_normal,tgm_simple=tri_model()\n",
    "#tgm_normal=clean_normal_corpus(tgm_normal,tgm_simple)\n",
    "X,Y=makexandy(tgm_normal,tgm_simple,glo_idx)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "model = LogisticRegression(lr=0.1, num_iter=3000)\n",
    "\n",
    "model.fit(X, Y)\n",
    "\n",
    "sentence=\"a city of Different kinds of formed by deck , truck the 1970s often have little or no concavity , whereas 1980s models have deeper concavities and steeper kicktails is a city.\"\n",
    "X_Test=makeXfortest(sentence,glo_idx)\n",
    "\n",
    "preds = model.predict(np.array(X))\n",
    "correct=0\n",
    "fp=0\n",
    "fn=0\n",
    "for i in range (0,len(preds)):\n",
    "    if preds[i]==Y[i]:\n",
    "        correct+=1\n",
    "    elif Y[i]==0:\n",
    "        fp+=1\n",
    "    else:\n",
    "        fn+=1\n",
    "print \"...........WITHOUT CLEANING...........\"\n",
    "print \"_____ACCURACY_____\"        \n",
    "print correct*1.0/len(Y)*100\n",
    "\n",
    "print \"_____PRECISION_____\"        \n",
    "precision = correct*1.0/(correct+fp)*100\n",
    "print precision\n",
    "\n",
    "print \"_____RECALL_____\"        \n",
    "recall = correct*1.0/(correct+fn)*100\n",
    "print recall\n",
    "\n",
    "print \"_____F1 SCORE_____\"\n",
    "f1 = 1/((1/precision)+(1/recall))\n",
    "print f1\n",
    "\n",
    "\n",
    "########################### CLEAN\n",
    "\n",
    "tgm_normal=clean_normal_corpus(tgm_normal,tgm_simple)\n",
    "X,Y=makexandy(tgm_normal,tgm_simple,glo_idx)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "model = LogisticRegression(lr=0.1, num_iter=3000)\n",
    "\n",
    "model.fit(X, Y)\n",
    "\n",
    "sentence=\"a city of Different kinds of formed by deck , truck the 1970s often have little or no concavity , whereas 1980s models have deeper concavities and steeper kicktails is a city.\"\n",
    "X_Test=makeXfortest(sentence,glo_idx)\n",
    "\n",
    "preds = model.predict(np.array(X))\n",
    "correct=0\n",
    "fp=0\n",
    "fn=0\n",
    "for i in range (0,len(preds)):\n",
    "    if preds[i]==Y[i]:\n",
    "        correct+=1\n",
    "    elif Y[i]==0:\n",
    "        fp+=1\n",
    "    else:\n",
    "        fn+=1\n",
    "print \".............WITH CLEANING...........\"\n",
    "print \"_____ACCURACY_____\"        \n",
    "print correct*1.0/len(Y)*100\n",
    "\n",
    "print \"_____PRECISION_____\"        \n",
    "precision = correct*1.0/(correct+fp)*100\n",
    "print precision\n",
    "\n",
    "print \"_____RECALL_____\"        \n",
    "recall = correct*1.0/(correct+fn)*100\n",
    "print recall\n",
    "\n",
    "print \"_____F1 SCORE_____\"\n",
    "f1 = 1/((1/precision)+(1/recall))\n",
    "print f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
